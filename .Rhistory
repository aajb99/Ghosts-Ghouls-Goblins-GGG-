plot(density(diff), xlab=expression(lambda[W] - lambda[M]), ylab="density", main=expression(paste("Posterior Distribution of ", lambda[W]-lambda[M])), lwd=2)
abline(v=0, lty=2)
# Posterior Dist on d = lambda_W - lambda_M:
# Monte Carlo Approx. to determine distribution of diff|data:
lambda.w <- rgamma(10000, gamma.p.w, phi.p.w)
lambda.m <- rgamma(10000, gamma.p.m, phi.p.m)
diff <- lambda.w - lambda.m
#Plot of the posterior on the difference
plot(density(diff), xlab=expression(lambda[W] - lambda[M]), ylab="density", main=expression(paste("Posterior Distribution of ", lambda[W]-lambda[M])), lwd=2)
abline(v=0, lty=2)
print(diff)
# Posterior Dist on d = lambda_W - lambda_M:
# Monte Carlo Approx. to determine distribution of diff|data:
lambda.w <- rgamma(10000, gamma.p.w, phi.p.w)
lambda.m <- rgamma(10000, gamma.p.m, phi.p.m)
diff <- lambda.w - lambda.m
#Plot of the posterior on the difference
plot(density(diff), xlab=expression(lambda[W] - lambda[M]), ylab="density", main=expression(paste("Posterior Distribution of ", lambda[W]-lambda[M])), lwd=2)
abline(v=0, lty=2)
mean(diff)
# Posterior Dist on d = lambda_W - lambda_M:
# Monte Carlo Approx. to determine distribution of diff|data:
lambda.w <- rgamma(10000, gamma.p.w, phi.p.w)
lambda.m <- rgamma(10000, gamma.p.m, phi.p.m)
diff <- lambda.w - lambda.m
#Plot of the posterior on the difference
plot(density(diff), xlab=expression(lambda[W] - lambda[M]), ylab="density", main=expression(paste("Posterior Distribution of ", lambda[W]-lambda[M])), lwd=2)
abline(v=0, lty=2)
mean_d <- mean(diff)
mean_d
knitr::opts_chunk$set(echo = TRUE)
#uncomment any of these that you will want to use (and add any others)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / (phi_1)^2
exp_val1
var1 <- gamma_1*(phi_1+1)/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1*(phi_1+1)/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(1.5, 6), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(1.5, 6), ylim=c(0, 1.2),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
# Prior distribution vs posterior distribution
curve(dgamma(x, gamma_1, phi_1), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="density",
main="Prior vs Posterior Distributions for # of Potholes per Block",
lwd=2)
curve(dgamma(x, gamma_post, phi_post), add=T, col="blue", lwd=2)
legend("topright", legend=c("Prior", "Posterior"), col=c("black", "blue"),
lwd=2, lty=c(1,1))
gamma_1 <- 0.5
phi_1 <- 0.5
exp_val1 <- gamma_1 / phi_1
exp_val1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 0.5"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(1.5, 6), ylim=c(0, 1.2),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
# Prior distribution vs posterior distribution
curve(dgamma(x, gamma_1, phi_1), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="density",
main="Prior vs Posterior Distributions for # of Potholes per Block",
lwd=2)
curve(dgamma(x, gamma_post, phi_post), add=T, col="blue", lwd=2)
legend("topright", legend=c("Prior", "Posterior"), col=c("black", "blue"),
lwd=2, lty=c(1,1))
exp_val_post <- gamma_post / phi_post
exp_val_post
# 95% Credible Interval
qgamma(c(.025, .975), gamma_post, phi_post)
# Posterior probability that the average number of potholes is greater than 4:
pgamma(4, gamma_post, phi_post, lower.tail=F)
# Posterior Predictive Distribution
# Monte Carlo approximation of pi(lambda|data)
lambda <- rgamma(10000, gamma_post, phi_post)
x_pred <- rpois(10000, lambda)
hist(x_pred, freq=F, ylim=c(0, 0.25), xlim=c(0, 15))
#posterior predictive probability that the number of potholes will be greater than 4 in a randomly selected block
prob_1g <- mean(x_pred > 4)
# Posterior Predictive Distribution
# Monte Carlo approximation of pi(lambda|data)
lambda <- rgamma(10000, gamma_post, phi_post)
x_pred <- rpois(10000, lambda)
hist(x_pred, freq=F, ylim=c(0, 0.25), xlim=c(0, 15))
#posterior predictive probability that the number of potholes will be greater than 4 in a randomly selected block
prob_1g <- mean(x_pred > 4)
prob_1g
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8", "Rate = 1.5"), col=c("black"),
lwd=2, lty=1)
data_w <- c(12, 9, 10, 8, 9, 4, 10, 15, 3, 5, 11, 8, 9, 4, 2, 7, 9,
5, 4, 2, 3, 12, 10, 2, 9, 8, 13, 9, 7, 6, 6, 2, 2, 6, 8)
data_m <- c(2, 3, 0, 4, 1, 1, 1, 2, 2, 2, 0, 3, 2)
sum_w <- sum(data_w)
sum_m <- sum(data_m)
gamma.p.w <- gamma_1 + sum_w
gamma.p.w
phi.p.w <- phi_1 + 35
phi.p.w
gamma.p.m <- gamma_1 + sum_m
gamma.p.m
phi.p.m <- phi_1 + 13
phi.p.m
curve(dgamma(x, shape = gamma.p.w, rate = phi.p.w), xlim = c(0, 10), ylim=c(0, 1.15),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution for Women vs Men", col="red", lwd=2)
curve(dgamma(x, shape = gamma.p.m, rate = phi.p.m), add = T, col="blue", lwd=2)
legend("topright", legend=c("Women", "Men"), col=c("red", "blue"),
lwd=2, lty=c(1,1))
# 95% Credible Intervals
# Women
qgamma(c(.025, .975), gamma.p.w, phi.p.w)
# Men
qgamma(c(.025, .975), gamma.p.m, phi.p.m)
# Posterior Dist on d = lambda_W - lambda_M:
# Monte Carlo Approx. to determine distribution of diff|data:
lambda.w <- rgamma(10000, gamma.p.w, phi.p.w)
lambda.m <- rgamma(10000, gamma.p.m, phi.p.m)
diff <- lambda.w - lambda.m
#Plot of the posterior on the difference
plot(density(diff), xlab=expression(lambda[W] - lambda[M]), ylab="density", main=expression(paste("Posterior Distribution of ", lambda[W]-lambda[M])), lwd=2)
abline(v=0, lty=2)
mean_d <- mean(diff)
mean_d
install.packages('themis')
#install.packages('tidyverse')
library(tidyverse)
#install.packages('tidymodels')
library(tidymodels)
#install.packages('DataExplorer')
#install.packages("poissonreg")
# library(poissonreg)
#install.packages("glmnet")
library(glmnet)
#library(patchwork)
# install.packages("rpart")
#install.packages('ranger')
library(ranger)
#install.packages('stacks')
library(stacks)
#install.packages('vroom')
library(vroom)
#install.packages('parsnip')
library(parsnip)
# install.packages('dbarts')
# library(dbarts)
#install.packages('embed')
library(embed)
library(themis)
qnorm(.95)
qnorm(.995)
qnorm(.9)
dnorm(x, 0, 1)
dnorm(x, mean = 0, sd = 1)
curve(dnorm(x, mean = 0, sd = 1), xlim = c(0, 10), ylim=c(0, 1.15), col="red", lwd=2)
curve(dnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(dnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(dnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(dnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(dnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(q, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(pnorm(q, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(q, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1.2), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-10, 10), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 24), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 24), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 10), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 10), ylim=c(0, .2), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 10), ylim=c(0, .5), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 100), ylim=c(0, .5), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 120), ylim=c(0, .45), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 120), ylim=c(0, .25), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 120), ylim=c(0, .25), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
# Normal Dist
1 - qnorm(.8643)
# Normal Dist
qnorm(.8643)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
#install.packages('tidyverse')
library(tidyverse)
#install.packages('tidymodels')
library(tidymodels)
#install.packages('DataExplorer')
#install.packages("poissonreg")
# library(poissonreg)
#install.packages("glmnet")
#library(glmnet)
#library(patchwork)
# install.packages("rpart")
#install.packages('ranger')
#library(ranger)
#install.packages('stacks')
#library(stacks)
#install.packages('vroom')
library(vroom)
#install.packages('parsnip')
#library(parsnip)
# install.packages('dbarts')
# library(dbarts)
#install.packages('embed')
#library(embed)
#library(themis)
setwd("~/byu_fall_2023/Stat_348/STAT348/Ghosts-Ghouls-Goblins-GGG-")
data_train <- vroom("./data/train.csv") %>%
mutate(type=factor(type))# grab training data
miss_val_data <- vroom("./data/trainWithMissingValues.csv") %>%
mutate(type=factor(type))# grab training data
rFormula <- type ~ .
## For target encoding/Random Forests: ###
missval_recipe <- recipe(rFormula, data = miss_val_data) %>% # set model formula and dataset
step_impute_linear(bone_length, impute_with = imp_vars(all_predictors())) %>%
step_impute_linear(rotting_flesh, impute_with = imp_vars(all_predictors())) %>%
step_impute_linear(hair_length, impute_with = imp_vars(all_predictors())) %>%
step_impute_linear(has_soul, impute_with = imp_vars(all_predictors()))
prepped_recipe <- prep(missval_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = miss_val_data)
install.packages('kknn')
library(kknn)
rFormula <- type ~ .
data_train
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(id)) %>% # get hours
step_pca(all_predictors(), threshold = 0.8) %>% # Threshold between 0 and 1, test run for classification rf
#step_smote(all_outcomes(), neighbors = 5)
prepped_recipe <- prep(my_recipe) # preprocessing new data
rFormula <- type ~ .
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(id)) %>% # get hours
step_pca(all_predictors(), threshold = 0.8) %>% # Threshold between 0 and 1, test run for classification rf
#step_smote(all_outcomes(), neighbors = 5)
prepped_recipe <- prep(my_recipe) # preprocessing new data
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(id)) %>% # get hours
step_pca(all_predictors(), threshold = 0.8) # Threshold between 0 and 1, test run for classification rf
#install.packages('tidyverse')
library(tidyverse)
#install.packages('tidymodels')
library(tidymodels)
#install.packages('DataExplorer')
#install.packages("poissonreg")
# library(poissonreg)
#install.packages("glmnet")
#library(glmnet)
#library(patchwork)
# install.packages("rpart")
#install.packages('ranger')
#library(ranger)
#install.packages('stacks')
#library(stacks)
#install.packages('vroom')
library(vroom)
#install.packages('parsnip')
library(parsnip)
# install.packages('dbarts')
library(dbarts)
#install.packages('embed')
library(embed)
library(themis)
data_train <- vroom("./data/train.csv") %>%
mutate(type=factor(type))# grab training data
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(id)) %>% # get hours
step_pca(all_predictors(), threshold = 0.8) # Threshold between 0 and 1, test run for classification rf
prepped_recipe <- prep(my_recipe) # preprocessing new data
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(id)) %>% # get hours
#step_pca(all_predictors(), threshold = 0.8) # Threshold between 0 and 1, test run for classification rf
#step_smote(all_outcomes(), neighbors = 5)
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(id)) #%>% # get hours
prepped_recipe <- prep(my_recipe) # preprocessing new data
data_train
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(type)) #%>% # get hours
prepped_recipe <- prep(my_recipe) # preprocessing new data
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(type)) %>% # get hours
#step_pca(all_predictors(), threshold = 0.8) # Threshold between 0 and 1, test run for classification rf
#step_smote(all_outcomes(), neighbors = 5)
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
## For target encoding ###
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
#step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_glm(color, outcome = vars(type)) %>% # get hours
#step_pca(all_predictors(), threshold = 0.8) # Threshold between 0 and 1, test run for classification rf
#step_smote(all_outcomes(), neighbors = 5)
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data_train)
library(kknn)
my_recipe_k <- my_recipe %>%
step_normalize()
prepped_recipe_k <- prep(my_recipe) # preprocessing new data
baked_data_k <- bake(prepped_recipe_k, new_data = data_train)
## knn model
knn_model <- nearest_neighbor(neighbors=tune()) %>% # set or tune
set_mode("classification") %>%
set_engine("kknn")
knn_wf <- workflow() %>%
add_recipe(my_recipe_k) %>%
add_model(knn_model)
## Fit or Tune MOdel
tuning_grid <- grid_regular(neighbors(),
levels = 5) ## L^2 total tuning possibilities
# Split data for CV
folds <- vfold_cv(data_train, v = 10, repeats = 1)
# Run CV
CV_results <- knn_wf %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(accuracy))
bestTune <- CV_results %>%
select_best('accuracy')
final_wf <- knn_wf %>%
finalize_workflow(bestTune) %>%
fit(data = data_train)
data_test <- vroom("./data/test.csv") # grab testing data
data_test <- vroom("./data/test.csv") # grab testing data
ggg_predictions <- predict(final_wf,
new_data=data_test,
type="class") %>% # "class" or "prob"
mutate(Id = data_test$id) %>%
#mutate(ACTION = ifelse(.pred_1 > .95, 1, 0)) %>%
mutate(ACTION = .pred_1) %>%
select(-.pred_0, -.pred_1)
ggg_predictions <- predict(final_wf,
new_data=data_test,
type="class") %>% # "class" or "prob"
mutate(Id = data_test$id) %>%
#mutate(ACTION = ifelse(.pred_1 > .95, 1, 0)) %>%
# mutate(ACTION = .pred_1) %>%
# select(-.pred_0, -.pred_1)
vroom_write(amazon_predictions, "./data/amazon_pred_knn2.csv", delim = ",")
ggg_predictions <- predict(final_wf,
new_data=data_test,
type="class") %>% # "class" or "prob"
mutate(Id = data_test$id)
ggg_predictions
ggg_predictions <- predict(final_wf,
new_data=data_test,
type="class") %>% # "class" or "prob"
mutate(id = data_test$id, type = .pred_class) %>%
select(id, type)
ggg_predictions
vroom_write(ggg_predictions, "./data/ggg_pred_knn.csv", delim = ",")
