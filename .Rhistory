var1 <- gamma_1*(phi_1+1)/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1*(phi_1+1)/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(1.5, 6), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(1.5, 6), ylim=c(0, 1.2),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
# Prior distribution vs posterior distribution
curve(dgamma(x, gamma_1, phi_1), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="density",
main="Prior vs Posterior Distributions for # of Potholes per Block",
lwd=2)
curve(dgamma(x, gamma_post, phi_post), add=T, col="blue", lwd=2)
legend("topright", legend=c("Prior", "Posterior"), col=c("black", "blue"),
lwd=2, lty=c(1,1))
gamma_1 <- 0.5
phi_1 <- 0.5
exp_val1 <- gamma_1 / phi_1
exp_val1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 0.5"), col=c("black"),
lwd=2, lty=1)
data_1 <- c(3, 3, 7, 1, 4, 6, 6, 7, 3, 1, 5, 5, 5, 3, 3, 0, 3, 1, 2, 2)
sum_x <- sum(data_1)
gamma_post <- gamma_1 + sum_x
gamma_post
phi_post <- phi_1 + 20
phi_post
curve(dgamma(x, shape = gamma_post, rate = phi_post), xlim = c(1.5, 6), ylim=c(0, 1.2),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 70.5, Rate = 20.5"), col=c("black"),
lwd=2, lty=1)
# Prior distribution vs posterior distribution
curve(dgamma(x, gamma_1, phi_1), xlim = c(0, 7), ylim=c(0, 1.5),
xlab=expression(lambda), ylab="density",
main="Prior vs Posterior Distributions for # of Potholes per Block",
lwd=2)
curve(dgamma(x, gamma_post, phi_post), add=T, col="blue", lwd=2)
legend("topright", legend=c("Prior", "Posterior"), col=c("black", "blue"),
lwd=2, lty=c(1,1))
exp_val_post <- gamma_post / phi_post
exp_val_post
# 95% Credible Interval
qgamma(c(.025, .975), gamma_post, phi_post)
# Posterior probability that the average number of potholes is greater than 4:
pgamma(4, gamma_post, phi_post, lower.tail=F)
# Posterior Predictive Distribution
# Monte Carlo approximation of pi(lambda|data)
lambda <- rgamma(10000, gamma_post, phi_post)
x_pred <- rpois(10000, lambda)
hist(x_pred, freq=F, ylim=c(0, 0.25), xlim=c(0, 15))
#posterior predictive probability that the number of potholes will be greater than 4 in a randomly selected block
prob_1g <- mean(x_pred > 4)
# Posterior Predictive Distribution
# Monte Carlo approximation of pi(lambda|data)
lambda <- rgamma(10000, gamma_post, phi_post)
x_pred <- rpois(10000, lambda)
hist(x_pred, freq=F, ylim=c(0, 0.25), xlim=c(0, 15))
#posterior predictive probability that the number of potholes will be greater than 4 in a randomly selected block
prob_1g <- mean(x_pred > 4)
prob_1g
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8"), col=c("black"),
lwd=2, lty=1)
gamma_1 <- 8
phi_1 <- 1.5
exp_val1 <- gamma_1 / phi_1
exp_val1
var1 <- gamma_1/(phi_1^2)
var1
curve(dgamma(x, shape = gamma_1, rate = phi_1), xlim = c(0, 16), ylim=c(0, .3),
xlab=expression(lambda), ylab="Density", main="A priori Gamma Distribution", lwd=2)
legend("topright", legend=c("Shape = 8", "Rate = 1.5"), col=c("black"),
lwd=2, lty=1)
data_w <- c(12, 9, 10, 8, 9, 4, 10, 15, 3, 5, 11, 8, 9, 4, 2, 7, 9,
5, 4, 2, 3, 12, 10, 2, 9, 8, 13, 9, 7, 6, 6, 2, 2, 6, 8)
data_m <- c(2, 3, 0, 4, 1, 1, 1, 2, 2, 2, 0, 3, 2)
sum_w <- sum(data_w)
sum_m <- sum(data_m)
gamma.p.w <- gamma_1 + sum_w
gamma.p.w
phi.p.w <- phi_1 + 35
phi.p.w
gamma.p.m <- gamma_1 + sum_m
gamma.p.m
phi.p.m <- phi_1 + 13
phi.p.m
curve(dgamma(x, shape = gamma.p.w, rate = phi.p.w), xlim = c(0, 10), ylim=c(0, 1.15),
xlab=expression(lambda), ylab="Density", main="Posterior Gamma Distribution for Women vs Men", col="red", lwd=2)
curve(dgamma(x, shape = gamma.p.m, rate = phi.p.m), add = T, col="blue", lwd=2)
legend("topright", legend=c("Women", "Men"), col=c("red", "blue"),
lwd=2, lty=c(1,1))
# 95% Credible Intervals
# Women
qgamma(c(.025, .975), gamma.p.w, phi.p.w)
# Men
qgamma(c(.025, .975), gamma.p.m, phi.p.m)
# Posterior Dist on d = lambda_W - lambda_M:
# Monte Carlo Approx. to determine distribution of diff|data:
lambda.w <- rgamma(10000, gamma.p.w, phi.p.w)
lambda.m <- rgamma(10000, gamma.p.m, phi.p.m)
diff <- lambda.w - lambda.m
#Plot of the posterior on the difference
plot(density(diff), xlab=expression(lambda[W] - lambda[M]), ylab="density", main=expression(paste("Posterior Distribution of ", lambda[W]-lambda[M])), lwd=2)
abline(v=0, lty=2)
mean_d <- mean(diff)
mean_d
install.packages('themis')
#install.packages('tidyverse')
library(tidyverse)
#install.packages('tidymodels')
library(tidymodels)
#install.packages('DataExplorer')
#install.packages("poissonreg")
# library(poissonreg)
#install.packages("glmnet")
library(glmnet)
#library(patchwork)
# install.packages("rpart")
#install.packages('ranger')
library(ranger)
#install.packages('stacks')
library(stacks)
#install.packages('vroom')
library(vroom)
#install.packages('parsnip')
library(parsnip)
# install.packages('dbarts')
# library(dbarts)
#install.packages('embed')
library(embed)
library(themis)
qnorm(.95)
qnorm(.995)
qnorm(.9)
dnorm(x, 0, 1)
dnorm(x, mean = 0, sd = 1)
curve(dnorm(x, mean = 0, sd = 1), xlim = c(0, 10), ylim=c(0, 1.15), col="red", lwd=2)
curve(dnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(dnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(dnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(dnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(dnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(q, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(pnorm(q, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(q, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1.2), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, .5), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-10, 10), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 24), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 24), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 10), ylim=c(0, 1), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 10), ylim=c(0, .2), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 10), ylim=c(0, .5), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(-1, 100), ylim=c(0, .5), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 120), ylim=c(0, .45), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 120), ylim=c(0, .25), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
curve(dgamma(x, shape = 4, rate = 1), xlim = c(0, 120), ylim=c(0, .25), col="red", lwd=2)
curve(dgamma(x, shape = 40, rate = 1), add = T, col="green", lwd=2)
curve(dgamma(x, shape = 80, rate = 1), add = T, col="blue", lwd=2)
# Normal Dist
1 - qnorm(.8643)
# Normal Dist
qnorm(.8643)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-12, 12), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = 0, sd = 4), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 0, sd = .25), add = T, col="blue", lwd=2)
curve(pnorm(x, mean = 0, sd = 1), xlim = c(-4, 4), ylim=c(0, 1), col="red", lwd=2)
curve(pnorm(x, mean = -1, sd = 1), add = T, col="green", lwd=2)
curve(pnorm(x, mean = 1, sd = 1), add = T, col="blue", lwd=2)
knitr::opts_chunk$set(echo = TRUE)
#uncomment any of these that you will want to use (and add any others)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
# Prior
mu_1 <- 1000
var_1 <- 200^2
cra_data <- c(1010, 1000, 950, 1050)
assumed_var <- var(cra_data)
assumed_var
# Prior
mu_1 <- 1000
var_1 <- 200^2
cra_data <- c(1010, 1000, 950, 1050)
n <- 4
assumed_var <- var(cra_data)
mu_post <- ((var_1 * sum(cra_data)) + (mu_1 * assumed_var)) / ((n * var_1) + assumed_var)
var_post <- (assumed_var * var_1) / ((n * var_1) + assumed_var)
mu_post
var_post
qnorm(c(.025, .975), mu_post)
# Distribution for calibrated date
caldate_mu <- 2203 - (0.835 * mu_post)
caldate_var <- (0.835^2) * var_post
caldate_mu
caldate_var
qnorm(c(.025, .975), caldate_mu)
library(invgamma)
knitr::opts_chunk$set(echo = TRUE)
#uncomment any of these that you will want to use (and add any others)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
install.packages("invgamma")
library(invgamma)
assumed_mu <- 80
# Prior
mu_1 <- 100
var_1 <- 500^2
gamma_1 <- 2.05
phi_1 <- mu_1*(gamma - 1)
assumed_mu <- 80
# Prior
mu_1 <- 100
var_1 <- 500^2
gamma_1 <- 2.05
phi_1 <- mu_1*(gamma_1 - 1)
### ### ###
# Collect data
grade_data <- c(90.5, 78.9, 92.5, 75.7, 59.5, 79.6, 76.3, 86.2)
n <- length(grade_data)
### ### ###
# Posterior
gamma_p <- gamma_1 + n/2
phi_p <- phi_1 + 0.5*sum((grade_data-assumed_mu)^2)
gamma_p
phi_p
# Posterior and prior distributions together
curve(dinvgamma(x, gamma_p, phi_p), xlim=c(0, 50), xlab=expression(sigma^2), ylab="Density", main="Posterior distribution of variance of grades", n=1000)
curve(dinvgamma(x, gamma_1, phi_1), lty=2, add=T)
legend("topright", c("Posterior", "Prior"), lty=c(1,2))
# Posterior and prior distributions together
curve(dinvgamma(x, gamma_p, phi_p), xlim=c(0, 100), xlab=expression(sigma^2), ylab="Density", main="Posterior distribution of variance of grades", n=1000)
curve(dinvgamma(x, gamma_1, phi_1), lty=2, add=T)
legend("topright", c("Posterior", "Prior"), lty=c(1,2))
# Posterior and prior distributions together
curve(dinvgamma(x, gamma_p, phi_p), xlim=c(0, 300), xlab=expression(sigma^2), ylab="Density", main="Posterior distribution of variance of grades", n=1000)
curve(dinvgamma(x, gamma_1, phi_1), lty=2, add=T)
legend("topright", c("Posterior", "Prior"), lty=c(1,2))
# Posterior and prior distributions together
curve(dinvgamma(x, gamma_p, phi_p), xlim=c(0, 350), xlab=expression(sigma^2), ylab="Density", main="Posterior distribution of variance of grades", n=1000)
curve(dinvgamma(x, gamma_1, phi_1), lty=2, add=T)
legend("topright", c("Posterior", "Prior"), lty=c(1,2))
# 95% CI for sigma (sd):
sqrt(qinvgamma(c(0.025, .975), gamma_p, phi_p))
# 95% CI for sigma (sd):
sqrt(qinvgamma(c(0.025, .975), gamma_p, phi_p))
qinvgamma(c(0.025, .975), gamma.p, phi.p)
# 95% CI for sigma (sd):
sqrt(qinvgamma(c(0.025, .975), gamma_p, phi_p))
qinvgamma(c(0.025, .975), gamma_p, phi_p)
# 95% CI for sigma (sd):
sqrt(qinvgamma(c(0.025, .975), gamma_p, phi_p))
# 95% CI for sigma^2 (var):
# qinvgamma(c(0.025, .975), gamma_p, phi_p)
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of milk ml")
#Posterior probability that X* > 90
# mean(sigma.vals > 3)
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of mommy milkers")
#Posterior probability that X* > 90
# mean(sigma.vals > 3)
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of grades")
#Posterior probability that X* > 90
# mean(sigma.vals > 3)
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of grades")
grades.vals <- rnorm(100000, mean = 80, sd = sigma.vals)
#Posterior probability that X* > 90
# mean(sigma.vals > 3)
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of grades")
grades.vals <- rnorm(100000, mean = 80, sd = sigma.vals)
plot(density(grades.vals), xlab='grades', ylab=expression(pi(X~"|data,"~mu)), main="Posterior on sd of grades")
#Posterior probability that X* > 90
# mean(sigma.vals > 3)
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of grades")
grades.vals <- rnorm(100000, mean = 80, sd = sigma.vals)
plot(density(grades.vals), xlab='grades', ylab=expression(pi(X>90~"|data,"~mu)), main="Posterior on grades given mean")
mean(grades.vals > 90)
#Posterior probability that X* > 90
# mean(sigma.vals > 3)
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of grades")
grades.vals <- rnorm(100000, mean = 80, sd = sigma.vals)
plot(density(grades.vals), xlab='grades', ylab=expression(pi(X*>90~"|data,"~mu)), main="Posterior on grades given mean")
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of grades")
grades.vals <- rnorm(100000, mean = 80, sd = sigma.vals)
plot(density(grades.vals), xlab='grades', ylab=expression(pi(X\*>90~"|data,"~mu)), main="Posterior on grades given mean")
# Plot normal distribution with given mu and posterior dist for var
sigma2.vals <- rinvgamma(100000, gamma_p, phi_p) #or 1/rgamma(100000, gamma.p, phi.p)
sigma.vals <- sqrt(sigma2.vals)
plot(density(sigma.vals), xlab=expression(sigma), ylab=expression(pi(sigma~"|data,"~mu)), main="Posterior on sd of grades")
grades.vals <- rnorm(100000, mean = 80, sd = sigma.vals)
plot(density(grades.vals), xlab='grades', ylab=expression(pi(X>90~"|data,"~mu)), main="Posterior on grades given mean")
mean(grades.vals > 90)
#Posterior probability that X* > 90
# mean(sigma.vals > 3)
setwd("C:/Users/aaron/Documents/byu_fall_2023/Stat_348/STAT348/Ghosts-Ghouls-Goblins-GGG-")
#install.packages('tidyverse')
library(tidyverse)
#install.packages('tidymodels')
library(tidymodels)
#install.packages('DataExplorer')
#install.packages("poissonreg")
# library(poissonreg)
#install.packages("glmnet")
#library(glmnet)
#library(patchwork)
# install.packages("rpart")
#install.packages('ranger')
#library(ranger)
#install.packages('stacks')
#library(stacks)
install.packages('vroom')
library(vroom)
install.packages('parsnip')
library(parsnip)
install.packages('dbarts')
library(dbarts)
install.packages('embed')
library(embed)
library(themis)
install.packages("parsnip")
data_train <- vroom("./data/train.csv") %>%
mutate(type=factor(type))# grab training data
rFormula <- type ~ .
nn_recipe <- recipe(rFormula, data= data_train) %>%
update_role(id, new_role="id") %>%
step_lencode_glm(color, outcome = vars(type)) %>% ## Turn color to factor then dummy encode color
step_dummy(all_nominal_predictors()) %>%
step_range(all_numeric_predictors(), min=0, max=1) #scale to [0,1]
nn_model <- mlp(hidden_units = tune(),
epochs = 50) %>% # RELU works comparatively well
set_engine("nnet") %>% #verbose = 0 prints off less
set_mode("classification")
nn_wf <- workflow() %>%
add_recipe(nn_recipe) %>%
add_model(nn_model)
nn_tuneGrid <- grid_regular(hidden_units(range=c(1, 10)),
levels=5)
# Split data for CV
folds <- vfold_cv(data_train, v = 5, repeats = 1)
# Run CV
tuned_nn <- nn_wf %>%
tune_grid(resamples = folds,
grid = nn_tuneGrid,
metrics = metric_set(accuracy))
# MLP in terms of accuracy
tuned_nn %>% collect_metrics() %>%
filter(.metric=="accuracy") %>%
ggplot(aes(x=hidden_units, y=mean)) + geom_line()
bestTune <- CV_results %>%
select_best('accuracy')
bestTune <- tuned_nn %>%
select_best('accuracy')
bestTune
final_wf <- nn_wf %>%
finalize_workflow(bestTune) %>%
fit(data = data_train)
## CV tune, finalize and predict here and save results22
## This takes a few min (10 on my laptop) so run it on becker if you want
# Kaggle DF
ggg_predictions_nn <- predict(final_wf,
new_data=data_test,
type="class") %>% # "class" or "prob"
mutate(id = data_test$id, type = .pred_class) %>%
select(id, type)
data_test <- vroom("./data/test.csv") # grab testing data
## CV tune, finalize and predict here and save results22
## This takes a few min (10 on my laptop) so run it on becker if you want
# Kaggle DF
ggg_predictions_nn <- predict(final_wf,
new_data=data_test,
type="class") %>% # "class" or "prob"
mutate(id = data_test$id, type = .pred_class) %>%
select(id, type)
vroom_write(ggg_predictions_nn, "./data/ggg_pred_nn.csv", delim = ",")
